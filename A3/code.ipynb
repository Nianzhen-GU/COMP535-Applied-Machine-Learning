{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.models import Model, load_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Input\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import BatchNormalization, Dropout,GaussianNoise\n",
    "from keras.layers import Flatten\n",
    "import tensorflow as tf\n",
    "from keras.initializers import glorot_normal, RandomNormal, Zeros\n",
    "import time\n",
    "from keras import regularizers, optimizers\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, Callback, EarlyStopping, LambdaCallback\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convert labels to 260 categories using one hot code"
   ],
   "metadata": {
    "id": "48sR9cA-CuDm"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def dimension_change(label):\n",
    "    digit = np.argmax(label[:10])\n",
    "    alpha = np.argmax(label[-26:])\n",
    "    new_index = digit*26+alpha\n",
    "    new_label = np.zeros(260)\n",
    "    new_label[new_index]=1\n",
    "    return new_label\n",
    "\n",
    "def label_change(x):\n",
    "    dim = len(x)\n",
    "    array = np.zeros([dim, 260])\n",
    "    for i in range(len(x)):\n",
    "        new_label = dimension_change(x[i])\n",
    "#         np.concatenate((array, new_label), axis=0)\n",
    "        array[i] = new_label\n",
    "    return array"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data"
   ],
   "metadata": {
    "id": "48sR9cA-CuDm"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def load_data():\n",
    "    with open('images_l.pkl', 'rb') as f:\n",
    "        trainX = pickle.load(f)\n",
    "\n",
    "    with open('labels_l.pkl', 'rb') as f:\n",
    "        label = pickle.load(f)\n",
    "\n",
    "    trainX = trainX.reshape((trainX.shape[0], 56, 56, 1))\n",
    "\n",
    "    trainX= trainX.astype('float32')\n",
    "    trainX = trainX / 255.0\n",
    "    \n",
    "    label = label_change(label)\n",
    "\n",
    "    print(trainX.shape)\n",
    "    print(label.shape)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(trainX, label, test_size=0.2, random_state=42)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define model"
   ],
   "metadata": {
    "id": "48sR9cA-CuDm"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def define_model():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(BatchNormalization(input_shape=(56, 56, 1)))\n",
    "\tmodel.add(GaussianNoise(0.1))\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(GaussianNoise(0.1))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(GaussianNoise(0.1))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Dropout(0.25))\n",
    "\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(GaussianNoise(0.1))\n",
    "\tmodel.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "\tmodel.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "\tmodel.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Dropout(0.25))\n",
    "\tmodel.add(GaussianNoise(0.05))\n",
    "\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(512, activation='relu'))\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(GaussianNoise(0.05))\n",
    "\tmodel.add(Dense(260, activation='softmax'))\n",
    "\t# compile model\n",
    "\t#opt = SGD(learning_rate=0.01, momentum=0.9)\n",
    "\tmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\treturn model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train the model and save the trained model"
   ],
   "metadata": {
    "id": "48sR9cA-CuDm"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lr_reduction = ReduceLROnPlateau(monitor='val_loss', patience=10, verbose=1, factor=.75)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "\n",
    "with tf.device('/device:GPU:0'):\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, y_train, y_test = load_data()\n",
    "    model = define_model()\n",
    "    print(model.summary())\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test),batch_size=128, epochs=120, callbacks=[lr_reduction, early_stopping])\n",
    "    end_time = time.time()\n",
    "    print(\"Trainig end! Time duration: \" + str(int(end_time-start_time)) + \" seconds\")\n",
    "    model.save(\"model1.h5\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Do the training on unlabeled data"
   ],
   "metadata": {
    "id": "48sR9cA-CuDm"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "loaded_model = tf.keras.models.load_model('model1.h5')\n",
    "\n",
    "with open('images_ul.pkl', 'rb') as f:\n",
    "    data_test = pickle.load(f)\n",
    "\n",
    "data_test= data_test.reshape((data_test.shape[0], 56, 56, 1))\n",
    "data_test= data_test.astype('float32')\n",
    "data_test = data_test / 255.0\n",
    "\n",
    "prediction = loaded_model.predict(data_test)\n",
    "def toNormalLabel(prediction):\n",
    "    string_list = []\n",
    "    for i in range(len(prediction)):\n",
    "        text = \"000000000000000000000000000000000000\"\n",
    "        s=list(text)\n",
    "        a = np.argmax(prediction[i])\n",
    "        alpha = int(a % 26)\n",
    "        digit = int((a-alpha) / 26)\n",
    "        s[digit]= \"1\"\n",
    "        s[10+alpha] = \"1\"\n",
    "        st = \"\".join(s)\n",
    "        string_list.append(st)\n",
    "    return string_list\n",
    "    \n",
    "output = toNormalLabel(prediction)  \n",
    "import pandas\n",
    "df = pandas.DataFrame(data={\"Category\": output})\n",
    "df[\"Category\"] = df[\"Category\"].apply(str) + '\\t'\n",
    "df\n",
    "df.to_csv(\"./images_l2.csv\",index=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load all data"
   ],
   "metadata": {
    "id": "48sR9cA-CuDm"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def load_data_all():\n",
    "    with open('images_l.pkl', 'rb') as f:\n",
    "        trainX = pickle.load(f)\n",
    "\n",
    "    with open('labels_l.pkl', 'rb') as f:\n",
    "        label = pickle.load(f)\n",
    "\n",
    "    with open('image_ul.pkl', 'rb') as f:\n",
    "        extra_trainX = pickle.load(f)\n",
    "\n",
    "    extra_label = pd.read_csv('images_l2.csv')\n",
    "\n",
    "    trainX = trainX + extra_trainX\n",
    "    label = label + extra_label\n",
    "\n",
    "    trainX = trainX.reshape((trainX.shape[0], 56, 56, 1))\n",
    "\n",
    "    trainX= trainX.astype('float32')\n",
    "    trainX = trainX / 255.0\n",
    "    \n",
    "    label = label_change(label)\n",
    "\n",
    "    print(trainX.shape)\n",
    "    print(label.shape)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(trainX, label, test_size=0.2, random_state=42)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Retrain the model using all data"
   ],
   "metadata": {
    "id": "48sR9cA-CuDm"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lr_reduction = ReduceLROnPlateau(monitor='val_loss', patience=10, verbose=1, factor=.75)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "\n",
    "with tf.device('/device:GPU:0'):\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, y_train, y_test = load_data_all()\n",
    "    model = define_model()\n",
    "    print(model.summary())\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test),batch_size=128, epochs=120, callbacks=[lr_reduction, early_stopping])\n",
    "    end_time = time.time()\n",
    "    print(\"Trainig end! Time duration: \" + str(int(end_time-start_time)) + \" seconds\")\n",
    "    model.save(\"model2.h5\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test and save result"
   ],
   "metadata": {
    "id": "48sR9cA-CuDm"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "loaded_model = tf.keras.models.load_model('model2.h5')\n",
    "\n",
    "with open('images_tets.pkl', 'rb') as f:\n",
    "    data_test = pickle.load(f)\n",
    "\n",
    "data_test= data_test.reshape((data_test.shape[0], 56, 56, 1))\n",
    "data_test= data_test.astype('float32')\n",
    "data_test = data_test / 255.0\n",
    "\n",
    "prediction = loaded_model.predict(data_test)\n",
    "def toNormalLabel(prediction):\n",
    "    string_list = []\n",
    "    for i in range(len(prediction)):\n",
    "        text = \"000000000000000000000000000000000000\"\n",
    "        s=list(text)\n",
    "        a = np.argmax(prediction[i])\n",
    "        alpha = int(a % 26)\n",
    "        digit = int((a-alpha) / 26)\n",
    "        s[digit]= \"1\"\n",
    "        s[10+alpha] = \"1\"\n",
    "        st = \"\".join(s)\n",
    "        string_list.append(st)\n",
    "    return string_list\n",
    "    \n",
    "output = toNormalLabel(prediction)  \n",
    "import pandas\n",
    "df = pandas.DataFrame(data={\"Category\": output})\n",
    "df[\"Category\"] = df[\"Category\"].apply(str) + '\\t'\n",
    "df\n",
    "df.to_csv(\"./submission.csv\",index=True)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}